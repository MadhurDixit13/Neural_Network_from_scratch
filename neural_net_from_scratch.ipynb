{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7chaybpQo_W",
        "outputId": "24db963e-3437-4389-de40-2417810c7252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(69)"
      ],
      "metadata": {
        "id": "aYJzy0IjQxMv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x is the input matrix, w is the weight matrix and b is the bias matrix\n",
        "def neuron(x, w, b):\n",
        "  return np.dot(x, w) + b"
      ],
      "metadata": {
        "id": "UgOBO1kWQ4rR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch inputs (original 0th layer inputs which is our actual data)\n",
        "# batches help in generalizing better to the dataset rather than giving a single input each time to fit\n",
        "# Selecting the correct batch size is the key if the batch size if too large and close to the actual size of data it will overfit to the training data as all the data is exposed at once while keeping batch size small will not fit to the entire data correctly as it will each time try to fit to single data points\n",
        "# Recommended batch sizes are 16, 32, 64 but depends on size of the data\n",
        "input = [[1,2,3], [2,3,4], [3,4,5]]\n",
        "weights1 = [[1,2,3],[2,3,4], [3,4,5]]\n",
        "bias1 = [1,2,3]\n",
        "weight2 = [[1,2,3],[2,3,4], [3,4,5]]\n",
        "bias2 = [1,2,3]\n",
        "layer1_output = neuron(input, weights1, bias1)\n",
        "layer2_output = neuron(layer1_output, weight2, bias2)\n",
        "layer2_output"
      ],
      "metadata": {
        "id": "T-fAxS30fXkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1554e6-2e54-469b-f792-e00453009958"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[147, 214, 281],\n",
              "       [207, 301, 395],\n",
              "       [267, 388, 509]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in layer1_output:\n",
        "  i = 1/(1+np.exp(-i))\n",
        "  print(i)\n",
        "for i in layer2_output:\n",
        "  i = 1/(1+np.exp(-i))\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "8KfV7ikefsry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c21ca0-3e3b-4c7a-e36c-d0054b978b72"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99999969 1.         1.        ]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x #original inputs\n",
        "    self.w = 0.1 * np.random.randn(len(x[0]), y) #randomized initial weights\n",
        "    self.b = np.zeros((1, y)) #randomized initial bias\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    self.output = np.dot(self.x, self.w) + self.b\n",
        "    return self.output\n",
        "  def backward(self, x):\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "1x2wnXfIGrQG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[1, 0.5, 0.3], [-0.2, 0.4, -0.67], [-0.9, 0.25, -0.77]]\n",
        "# print(0.1* np.random.randn(len(x[0]),4))\n",
        "# print(np.zeros((1,4)))\n",
        "layer1 = Layer(x, 4)\n",
        "output = layer1.forward(x)"
      ],
      "metadata": {
        "id": "isF6Loul_ElV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6bXfMyzBm0Z",
        "outputId": "70bdddc6-03c0-4e90-8269-86ef1fd1f1eb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03725274, -0.01978615,  0.16978068, -0.02299052],\n",
              "       [-0.13933001, -0.01820934,  0.0400461 ,  0.08926617],\n",
              "       [-0.18797866,  0.01117879, -0.05715518,  0.12074152]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5KUVVShDw8T"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}